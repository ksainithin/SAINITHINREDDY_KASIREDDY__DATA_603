{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa49227a-eb94-44b2-adb7-5b988a8068a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.2-py3-none-any.whl.metadata (9.4 kB)\n",
      "Downloading pyspellchecker-0.8.2-py3-none-any.whl (7.1 MB)\n",
      "   ---------------------------------------- 0.0/7.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.1 MB 435.7 kB/s eta 0:00:17\n",
      "    --------------------------------------- 0.1/7.1 MB 939.4 kB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.2/7.1 MB 1.4 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.4/7.1 MB 1.8 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.5/7.1 MB 2.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.6/7.1 MB 2.2 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.8/7.1 MB 2.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.0/7.1 MB 2.6 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.2/7.1 MB 2.8 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.3/7.1 MB 2.9 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.6/7.1 MB 3.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.7/7.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.9/7.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.1/7.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.2/7.1 MB 3.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.3/7.1 MB 3.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 2.5/7.1 MB 3.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 2.7/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.9/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 3.0/7.1 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.2/7.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 3.3/7.1 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.5/7.1 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 3.7/7.1 MB 3.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 3.8/7.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 4.0/7.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 4.2/7.1 MB 3.6 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 4.4/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.5/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 4.6/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.8/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 4.9/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 5.0/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 5.3/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 5.4/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 5.6/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 5.8/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.9/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.1/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 6.2/7.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.5/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.7/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.8/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.0/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.1/7.1 MB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.1/7.1 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e9c79f-1594-4504-8efe-dd81abd27d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Words in file1.txt:\n",
      "trickier: 1\n",
      "than: 5\n",
      "i: 17\n",
      "expected: 1\n",
      "but: 9\n",
      "hope: 1\n",
      "he: 17\n",
      "will: 10\n",
      "be: 18\n",
      "satisfied: 1\n",
      "y: 21\n",
      "ou: 2\n",
      "sound: 3\n",
      "confident: 1\n",
      "that: 21\n",
      "your: 1\n",
      "reception: 1\n",
      "good: 4\n",
      "p: 6\n",
      "a: 39\n",
      "g: 6\n",
      "e: 8\n",
      "2: 1\n",
      "harry: 11\n",
      "potter: 14\n",
      "and: 31\n",
      "the: 118\n",
      "deathly: 6\n",
      "hallows: 6\n",
      "j: 6\n",
      "k: 6\n",
      "rowling: 6\n",
      "snape: 17\n",
      "nodded: 1\n",
      "did: 5\n",
      "not: 9\n",
      "elaborate: 1\n",
      "they: 9\n",
      "turned: 5\n",
      "right: 4\n",
      "into: 5\n",
      "wide: 1\n",
      "driveway: 1\n",
      "led: 1\n",
      "of: 47\n",
      "f: 2\n",
      "lane: 1\n",
      "high: 3\n",
      "hedge: 3\n",
      "curved: 2\n",
      "with: 10\n",
      "them: 6\n",
      "running: 1\n",
      "distance: 2\n",
      "beyond: 2\n",
      "pair: 1\n",
      "impressive: 1\n",
      "wrought: 1\n",
      "iron: 1\n",
      "gates: 1\n",
      "barring: 1\n",
      "men: 4\n",
      "s: 10\n",
      "way: 2\n",
      "neither: 1\n",
      "broke: 1\n",
      "step: 1\n",
      "in: 14\n",
      "silence: 1\n",
      "both: 1\n",
      "raised: 1\n",
      "their: 6\n",
      "left: 1\n",
      "arms: 1\n",
      "kind: 1\n",
      "salute: 1\n",
      "passed: 1\n",
      "straight: 2\n",
      "through: 3\n",
      "as: 11\n",
      "though: 2\n",
      "dark: 2\n",
      "metal: 1\n",
      "were: 3\n",
      "smoke: 1\n",
      "yew: 1\n",
      "hedges: 1\n",
      "muf: 1\n",
      "fled: 1\n",
      "footsteps: 1\n",
      "there: 7\n",
      "was: 11\n",
      "rustle: 1\n",
      "somewhere: 2\n",
      "to: 36\n",
      "axley: 18\n",
      "drew: 2\n",
      "his: 16\n",
      "wand: 2\n",
      "again: 3\n",
      "pointing: 1\n",
      "it: 12\n",
      "over: 2\n",
      "companion: 1\n",
      "head: 3\n",
      "source: 4\n",
      "noise: 1\n",
      "proved: 1\n",
      "nothing: 1\n",
      "more: 4\n",
      "pure: 1\n",
      "white: 2\n",
      "peacock: 1\n",
      "strutting: 1\n",
      "majestically: 1\n",
      "along: 2\n",
      "top: 1\n",
      "always: 1\n",
      "himself: 4\n",
      "well: 1\n",
      "lucius: 1\n",
      "peacocks: 1\n",
      "www: 10\n",
      "ztcprep: 10\n",
      "com: 10\n",
      "thrust: 1\n",
      "back: 5\n",
      "under: 2\n",
      "cloak: 1\n",
      "snort: 1\n",
      "handsome: 2\n",
      "manor: 1\n",
      "house: 1\n",
      "grew: 2\n",
      "out: 3\n",
      "darkness: 1\n",
      "at: 18\n",
      "end: 1\n",
      "drive: 1\n",
      "lights: 1\n",
      "glinting: 2\n",
      "diamond: 1\n",
      "paned: 1\n",
      "downstairs: 1\n",
      "windows: 1\n",
      "garden: 1\n",
      "fountain: 1\n",
      "playing: 1\n",
      "gravel: 1\n",
      "crackled: 1\n",
      "beneath: 2\n",
      "feet: 1\n",
      "sped: 1\n",
      "toward: 1\n",
      "front: 2\n",
      "door: 2\n",
      "which: 2\n",
      "swung: 1\n",
      "inward: 1\n",
      "approach: 1\n",
      "nobody: 1\n",
      "had: 5\n",
      "visibly: 1\n",
      "opened: 1\n",
      "hallway: 1\n",
      "lar: 2\n",
      "ge: 2\n",
      "dimly: 1\n",
      "lit: 1\n",
      "sumptuously: 1\n",
      "decorated: 1\n",
      "magnificent: 1\n",
      "carpet: 1\n",
      "covering: 1\n",
      "most: 2\n",
      "stone: 1\n",
      "floor: 1\n",
      "eyes: 6\n",
      "pale: 3\n",
      "faced: 1\n",
      "portraits: 1\n",
      "on: 10\n",
      "walls: 2\n",
      "followed: 2\n",
      "strode: 1\n",
      "past: 1\n",
      "two: 3\n",
      "halted: 1\n",
      "heavy: 1\n",
      "wooden: 1\n",
      "leading: 1\n",
      "next: 6\n",
      "room: 3\n",
      "hesitated: 1\n",
      "for: 7\n",
      "space: 1\n",
      "heartbeat: 1\n",
      "then: 4\n",
      "bronze: 1\n",
      "handle: 1\n",
      "drawing: 1\n",
      "full: 1\n",
      "silent: 1\n",
      "people: 4\n",
      "sitting: 4\n",
      "long: 5\n",
      "ornate: 1\n",
      "table: 11\n",
      "usual: 1\n",
      "furniture: 1\n",
      "3: 1\n",
      "been: 8\n",
      "pushed: 1\n",
      "carelessly: 1\n",
      "up: 3\n",
      "against: 1\n",
      "illumination: 1\n",
      "came: 1\n",
      "from: 6\n",
      "roaring: 1\n",
      "fire: 1\n",
      "marble: 1\n",
      "mantelpiece: 1\n",
      "surmounted: 1\n",
      "by: 9\n",
      "gilded: 1\n",
      "mirror: 2\n",
      "lingered: 1\n",
      "moment: 2\n",
      "threshold: 1\n",
      "accustomed: 1\n",
      "lack: 1\n",
      "light: 1\n",
      "drawn: 2\n",
      "upward: 3\n",
      "strangest: 1\n",
      "feature: 1\n",
      "scene: 1\n",
      "an: 5\n",
      "apparently: 2\n",
      "unconscious: 2\n",
      "human: 1\n",
      "figure: 1\n",
      "hanging: 1\n",
      "upside: 1\n",
      "down: 4\n",
      "revolving: 3\n",
      "slowly: 3\n",
      "if: 4\n",
      "suspended: 1\n",
      "invisible: 1\n",
      "rope: 1\n",
      "reflected: 1\n",
      "bare: 1\n",
      "polished: 1\n",
      "surface: 1\n",
      "below: 2\n",
      "none: 1\n",
      "seated: 2\n",
      "underneath: 1\n",
      "this: 3\n",
      "singular: 1\n",
      "sight: 1\n",
      "looking: 1\n",
      "except: 1\n",
      "young: 1\n",
      "man: 4\n",
      "almost: 1\n",
      "directly: 2\n",
      "seemed: 7\n",
      "unable: 1\n",
      "prevent: 1\n",
      "glancing: 1\n",
      "every: 2\n",
      "minute: 1\n",
      "or: 5\n",
      "so: 6\n",
      "said: 12\n",
      "clear: 1\n",
      "voice: 1\n",
      "are: 4\n",
      "very: 1\n",
      "nearly: 1\n",
      "late: 1\n",
      "speaker: 1\n",
      "fireplace: 1\n",
      "dif: 3\n",
      "ficult: 1\n",
      "first: 3\n",
      "new: 1\n",
      "arrivals: 1\n",
      "make: 1\n",
      "silhouette: 1\n",
      "nearer: 1\n",
      "however: 3\n",
      "face: 3\n",
      "shone: 1\n",
      "gloom: 1\n",
      "hairless: 1\n",
      "snakelike: 1\n",
      "slits: 1\n",
      "nostrils: 1\n",
      "gleaming: 1\n",
      "red: 3\n",
      "whose: 1\n",
      "pupils: 1\n",
      "vertical: 1\n",
      "emit: 1\n",
      "pearly: 1\n",
      "glow: 1\n",
      "severus: 1\n",
      "here: 2\n",
      "v: 19\n",
      "oldemort: 18\n",
      "indicating: 1\n",
      "seat: 1\n",
      "immediate: 1\n",
      "beside: 1\n",
      "dolohov: 2\n",
      "took: 1\n",
      "allotted: 1\n",
      "places: 1\n",
      "around: 4\n",
      "him: 5\n",
      "spoke: 1\n",
      "my: 12\n",
      "lord: 9\n",
      "order: 6\n",
      "phoenix: 1\n",
      "intends: 1\n",
      "move: 2\n",
      "current: 1\n",
      "place: 3\n",
      "safety: 1\n",
      "saturday: 5\n",
      "nightfall: 2\n",
      "4: 1\n",
      "interest: 1\n",
      "sharpened: 1\n",
      "palpably: 1\n",
      "some: 4\n",
      "stif: 1\n",
      "fened: 1\n",
      "others: 2\n",
      "fidgeted: 1\n",
      "all: 7\n",
      "gazing: 1\n",
      "repeated: 1\n",
      "fastened: 1\n",
      "upon: 3\n",
      "black: 1\n",
      "ones: 1\n",
      "such: 2\n",
      "intensity: 1\n",
      "watchers: 1\n",
      "looked: 5\n",
      "away: 1\n",
      "fearful: 1\n",
      "themselves: 1\n",
      "would: 2\n",
      "scorched: 1\n",
      "ferocity: 1\n",
      "gaze: 2\n",
      "calmly: 1\n",
      "after: 2\n",
      "lipless: 1\n",
      "mouth: 1\n",
      "something: 1\n",
      "like: 1\n",
      "smile: 1\n",
      "ery: 1\n",
      "information: 1\n",
      "comes: 1\n",
      "we: 5\n",
      "discussed: 1\n",
      "leaned: 1\n",
      "forward: 1\n",
      "look: 1\n",
      "faces: 1\n",
      "have: 12\n",
      "heard: 1\n",
      "ferently: 1\n",
      "waited: 1\n",
      "speak: 1\n",
      "went: 3\n",
      "dawlish: 4\n",
      "auror: 2\n",
      "let: 1\n",
      "slip: 1\n",
      "moved: 1\n",
      "until: 1\n",
      "thirtieth: 1\n",
      "night: 1\n",
      "before: 6\n",
      "boy: 5\n",
      "turns: 1\n",
      "seventeen: 1\n",
      "smiling: 1\n",
      "told: 1\n",
      "me: 2\n",
      "plans: 2\n",
      "lay: 1\n",
      "false: 1\n",
      "trail: 1\n",
      "must: 4\n",
      "no: 2\n",
      "doubt: 1\n",
      "confundus: 1\n",
      "charm: 1\n",
      "has: 6\n",
      "placed: 1\n",
      "time: 1\n",
      "is: 12\n",
      "known: 1\n",
      "susceptible: 1\n",
      "assure: 2\n",
      "you: 3\n",
      "quite: 1\n",
      "certain: 2\n",
      "5: 1\n",
      "confunded: 1\n",
      "naturally: 1\n",
      "fice: 1\n",
      "play: 1\n",
      "further: 1\n",
      "part: 1\n",
      "protection: 2\n",
      "believes: 2\n",
      "infiltrated: 1\n",
      "ministry: 7\n",
      "got: 1\n",
      "one: 5\n",
      "thing: 1\n",
      "eh: 1\n",
      "squat: 1\n",
      "short: 1\n",
      "gave: 1\n",
      "wheezy: 1\n",
      "giggle: 1\n",
      "echoed: 1\n",
      "laugh: 1\n",
      "wandered: 1\n",
      "body: 3\n",
      "overhead: 1\n",
      "lost: 1\n",
      "thought: 1\n",
      "entire: 1\n",
      "party: 1\n",
      "aurors: 1\n",
      "used: 1\n",
      "transfer: 1\n",
      "held: 1\n",
      "hand: 1\n",
      "subsided: 1\n",
      "once: 3\n",
      "watching: 1\n",
      "resentfully: 1\n",
      "where: 2\n",
      "going: 1\n",
      "hide: 1\n",
      "home: 1\n",
      "according: 1\n",
      "given: 1\n",
      "together: 2\n",
      "could: 1\n",
      "provide: 1\n",
      "think: 2\n",
      "little: 1\n",
      "chance: 2\n",
      "taking: 1\n",
      "unless: 1\n",
      "course: 1\n",
      "fallen: 2\n",
      "might: 2\n",
      "give: 1\n",
      "us: 1\n",
      "opportunity: 1\n",
      "discover: 1\n",
      "undo: 1\n",
      "enough: 1\n",
      "enchantments: 1\n",
      "break: 1\n",
      "rest: 2\n",
      "w: 4\n",
      "ell: 1\n",
      "called: 1\n",
      "firelight: 1\n",
      "strangely: 1\n",
      "ill: 1\n",
      "6: 1\n",
      "heads: 2\n",
      "squared: 1\n",
      "shoulders: 1\n",
      "news: 1\n",
      "score: 1\n",
      "ficulty: 1\n",
      "great: 1\n",
      "ef: 1\n",
      "fort: 1\n",
      "suceeded: 1\n",
      "placing: 1\n",
      "imperius: 1\n",
      "curse: 1\n",
      "pius: 1\n",
      "thicknesse: 4\n",
      "many: 3\n",
      "those: 4\n",
      "impressed: 1\n",
      "neighbor: 1\n",
      "twisted: 1\n",
      "clapped: 1\n",
      "start: 1\n",
      "only: 2\n",
      "scrimgeour: 2\n",
      "surrounded: 1\n",
      "our: 3\n",
      "act: 1\n",
      "failed: 1\n",
      "attempt: 1\n",
      "minister: 2\n",
      "life: 1\n",
      "set: 1\n",
      "es: 1\n",
      "true: 1\n",
      "know: 3\n",
      "department: 2\n",
      "magical: 2\n",
      "law: 1\n",
      "enforcement: 1\n",
      "regular: 1\n",
      "contact: 1\n",
      "also: 1\n",
      "other: 1\n",
      "departments: 1\n",
      "easy: 1\n",
      "now: 3\n",
      "ranking: 1\n",
      "ficial: 1\n",
      "control: 1\n",
      "subjugate: 1\n",
      "can: 1\n",
      "work: 1\n",
      "bring: 1\n",
      "friend: 1\n",
      "discovered: 1\n",
      "converted: 1\n",
      "any: 3\n",
      "rate: 1\n",
      "remains: 1\n",
      "unlikely: 1\n",
      "mine: 1\n",
      "cannot: 1\n",
      "touch: 1\n",
      "destination: 1\n",
      "done: 1\n",
      "while: 1\n",
      "travels: 1\n",
      "advantage: 1\n",
      "who: 1\n",
      "determined: 1\n",
      "receive: 1\n",
      "portion: 1\n",
      "approval: 1\n",
      "several: 1\n",
      "planted: 1\n",
      "within: 1\n",
      "t: 1\n",
      "ransport: 1\n",
      "apparates: 1\n",
      "uses: 1\n",
      "floo: 1\n",
      "network: 1\n",
      "shall: 3\n",
      "immediately: 1\n",
      "7: 1\n",
      "do: 2\n",
      "either: 1\n",
      "eschewing: 1\n",
      "form: 1\n",
      "transport: 1\n",
      "controlled: 1\n",
      "regulated: 1\n",
      "mistrust: 1\n",
      "everything: 1\n",
      "better: 2\n",
      "open: 1\n",
      "easier: 1\n",
      "take: 1\n",
      "far: 1\n",
      "attend: 1\n",
      "person: 1\n",
      "too: 1\n",
      "mistakes: 1\n",
      "concerned: 1\n",
      "own: 1\n",
      "lives: 1\n",
      "due: 1\n",
      "errors: 1\n",
      "triumphs: 1\n",
      "company: 1\n",
      "watched: 1\n",
      "apprehensively: 1\n",
      "each: 1\n",
      "her: 1\n",
      "expression: 1\n",
      "afraid: 1\n",
      "blamed: 1\n",
      "continued: 1\n",
      "existence: 1\n",
      "speaking: 1\n",
      "still: 1\n",
      "addressing: 1\n",
      "above: 1\n",
      "careless: 1\n",
      "thwarted: 1\n",
      "luck: 1\n",
      "wreckers: 1\n",
      "best: 1\n",
      "laid: 1\n",
      "understand: 2\n",
      "things: 1\n",
      "kill: 1\n",
      "these: 1\n",
      "words: 1\n",
      "seemingly: 1\n",
      "response: 1\n",
      "sudden: 1\n",
      "wail: 1\n",
      "sounded: 1\n",
      "terrible: 1\n",
      "cry: 1\n",
      "misery: 1\n",
      "pain: 1\n",
      "downward: 1\n",
      "startled: 1\n",
      "\n",
      "All Non-English Words in file2.txt:\n",
      "ve: 1\n",
      "yeh: 1\n",
      "shunpike: 1\n",
      "eagled: 1\n",
      "oldemort: 1\n",
      "lamplit: 1\n",
      "eal: 1\n",
      "onks: 1\n",
      "hagrid: 1\n",
      "shouldn: 1\n",
      "easley: 1\n",
      "thestral: 1\n",
      "didn: 1\n",
      "selwyn: 1\n",
      "ter: 1\n",
      "arrior: 1\n",
      "accio: 1\n",
      "expelliarmus: 1\n",
      "meself: 1\n",
      "www: 1\n",
      "ztcprep: 1\n",
      "ith: 1\n",
      "emer: 1\n",
      "muggle: 1\n",
      "vada: 1\n",
      "ged: 1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "from PyPDF2 import PdfReader\n",
    "from spellchecker import SpellChecker  # To check for non-English words\n",
    "\n",
    "# My Date of birth \n",
    "BIRTH_MONTH = 7   # July (7th month)\n",
    "BIRTH_DAY = 2   # 2nd day\n",
    "BIRTH_YEAR = 2002  # 2002 year\n",
    "\n",
    "# harry potter books and pages to extract based on birth month and year\n",
    "BOOK_START_PAGE = {1: 0, 2: 800, 3: 1600, 4: 2400, 5: 3200, 6: 4000, 7: 5944}\n",
    "\n",
    "# Calculating the book and start pages\n",
    "book_number = 7 \n",
    "book_start_page = BOOK_START_PAGE[book_number]\n",
    "start_page_for_day = book_start_page + BIRTH_DAY\n",
    "start_page_for_year = book_start_page + (100 + (BIRTH_YEAR % 100))\n",
    "\n",
    "# Extract text from the given pages\n",
    "def extract_pages(pdf_path, start, end):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = []\n",
    "    for i in range(start, end):\n",
    "        if i < len(reader.pages):\n",
    "            text.append(reader.pages[i].extract_text())\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "# Extracting file1.txt and file2.txt\n",
    "pdf_file = \"Harry_Potter.pdf\"\n",
    "file1_text = extract_pages(pdf_file, start_page_for_day, start_page_for_day + 10)\n",
    "file2_text = extract_pages(pdf_file, start_page_for_year, start_page_for_year + 10)\n",
    "\n",
    "with open(\"file1.txt\", \"w\", encoding=\"utf-8\") as f1:\n",
    "    f1.write(file1_text)\n",
    "\n",
    "with open(\"file2.txt\", \"w\", encoding=\"utf-8\") as f2:\n",
    "    f2.write(file2_text)\n",
    "\n",
    "#Q1)Write Python code and use MapReduct to count occurrences of each word in the first text file (file.txt). How many times each word is repeated?\n",
    "# Function to count word occurrences in file1.txt (MapReduce)\n",
    "def map_reduce_word_count(file_path):\n",
    "    word_count = defaultdict(int)\n",
    "    \n",
    "    # Map phase\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', text.lower())  \n",
    "        for word in words:\n",
    "            word_count[word] += 1\n",
    "    \n",
    "    # Return the word count for all words\n",
    "    return word_count\n",
    "\n",
    "#Q2) From the second text file (file2.txt), write Python code and use MapReduct to count how many times non-English words (names, places, spells etc.) were used. List those words and how many times each was repeated.\n",
    "# Function to check for non-English words using pyspellchecker (MapReduce)\n",
    "def map_reduce_non_english_count(file_path):\n",
    "    spell = SpellChecker()\n",
    "    non_english_count = defaultdict(int)\n",
    "    \n",
    "    # Map phase\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        misspelled = spell.unknown(words)\n",
    "        for word in misspelled:\n",
    "            non_english_count[word.lower()] += 1\n",
    "    \n",
    "    #  the count for all non-English words\n",
    "    return non_english_count\n",
    "\n",
    "# Running the MapReduce analysis\n",
    "file1_word_counts = map_reduce_word_count(\"file1.txt\")\n",
    "file2_non_english_counts = map_reduce_non_english_count(\"file2.txt\")\n",
    "\n",
    "\n",
    "print(\"All Words in file1.txt:\")\n",
    "for word, count in file1_word_counts.items():\n",
    "    print(f\"{word}: {count}\")\n",
    "\n",
    "print(\"\\nAll Non-English Words in file2.txt:\")\n",
    "for word, count in file2_non_english_counts.items():\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8435459-8391-4475-9c54-529dd2a9a1d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74c7d9b-c1f7-4780-b439-6cb7f82bdb52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075b9e4-3f49-467b-9531-dccfdea62801",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
